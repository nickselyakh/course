\chapter{Обзор литературы}\label{chap1}


В настоящей главе приводится обзор основных результатов теории оптимального управления. Сначала обсуждаются формулировки задач, возникающих при оптимизации динамических систем управления. Затем приводятся основные результаты качественной теории --- принцип максимума Л.С. Понтрягина \cite{Pontryagin} и динамическое программирование Р. Беллмана \cite{Bellman}.

В данной главе рассматриваются основные результаты теории оптимального управления, классический подход к построению обратных связей, а также оптимальное управление в реальном времени и реализация оптимальной обратной связи

Кроме того, обсуждаются современные методы управления в реальном времени: реализация оптимальных обратных связей в задачах оптимального управления с конечным горизонтом и теория управления по прогнозирующей модели для решения классической проблемы теории управления  --- стабилизации нелинейных динамических систем при наличии ограничений.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Синтез дискретных систем}\label{1sec:snth}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Синтез ДС сводится к выбору управляющего устройства, которое образует с объектом управления некую структуру, позволяющую получить систему с желаемыми характеристиками, под которыми понимаются интересующие разработчика определённые показатели качества. Таким образом, перед разработчиками ставятся задачи синтеза функциональной структуры ДС (приборный синтез) и синтеза корректирующего устройства.
% Приборный синтез состоит в выборе элементов и структуры регулятора, обеспечивающего принцип действия системы. При этом должны обеспечиваться технические условия их нормальной работы при совместном включении. Обычно разработчик на данном этапе использует сведения о параметрах протекающих процессов, физической природе переменных измерения и управления, а также имеющихся технических средствах. Полученные на этом этапе объект или часть ДС называют неизменяемой системой. Этот этап проектирования не имеет пока строгой математической основы и относится к области инженерного искусства.
% Корректирующий синтез подразумевает введение таких добавочных устройств, которые улучшат качество работы неизменяемой системы и при этом не нарушат принципиальной работоспособности устройства. Из теории непрерывных систем управления известно, что коррекция может быть последовательная, параллельная, коррекция за счёт введения обратной связи и смешанная. С математических позиций все они эквивалентны, так как корректирующему контуру одного типа может быть сопоставлен корректирующий контур другого типа.
% Важнейшим этапом проектирования ДС является разработка цифровых законов управления непрерывными объектами. Для решения этой задачи предложено три подхода: 1) переоборудование, которое сводится к замене непрерывного регулятора его дискретной моделью в результате аппроксимации; 2) дискретизация объекта путём построения дискретной модели непрерывного объекта и последующий синтез регулятора методами теории дискретных систем; 3) прямой синтез цифрового регулятора для непрерывного объекта без каких-либо упрощений и аппроксимаций.
% Первые два подхода являются приближёнными и фактически предполагают замену одной задачи другой с целью применить известные результаты теории стационарных (непрерывных или дискретных) систем.   В первом подходе игнорируется наличие цифровой части (импульсного элемента, дискретного регулятора и экстраполятора) с помощью дискретного преобразования Лапласа и используются методы синтеза непрерывных систем. При этом иногда дискретизация полученного аналогового регулятора не позволяет добиться желаемого эффекта. При использовании

% второго подхода не учитывается поведение системы в промежутках между моментами квантования, что может привести к появлению скрытых колебаний и несоответствию качества полученной системы заданным критериям. Другой недостаток метода дискретизации объекта состоит в том, что требования к системе, сформулированные в непрерывном времени, не всегда легко перевести в соответствующие дискретизированные показатели качества. На современном этапе в теории дискретных систем управления основное внимание уделяется точным методам анализа и синтеза. Во многом это связано с тем, что приближённые методы проектирования могут приводить к неработоспособным решениям.
% Применительно к первым двум подходам разработаны определённые методы синтеза, которые позволяют получить выражение для реализации регулятора. К этим методам относятся [13]:
% 	•	графоаналитические методы инженерного динамического синтеза САУ: корневые, корневого годографа, стандартных переходных характеристик, частотные;
% 	•	аналитические методы оптимального и адаптивного управления;
% 	•	синтез САУ по интегральным критериям качества (функционалам) методами вариационного исчисления, динамического линейного и нелинейного математического программирования, принципом максимума Понтрягина, методом Винера-Хопфа, методами модального управления, методами аналитического конструирования оптимальных регуляторов и др.
% Для третьего подхода применяются ЭВМ с использованием специализированного программного обеспечения на основе методов аналогового и цифрового моделирования САУ. По сравнению с первыми двумя методами здесь реализуется наиболее полное исследование свойств и синтез САУ с учётом  всех  особенностей  объекта  управления.  Аналитические и графоаналитические методы, в свою очередь, позволяют исследовать САУ в более общем виде и найти оптимальный вариант среди множества решений.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Основные результаты теории оптимального управления}\label{1sec:optimal-control}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Постановка любой конкретной задачи оптимального управления включает в себя 5 необходимых элементов: промежуток управления, математическую модель управляемого объекта, класс управлений и ограничений на них, ограничения на фазовую траекторию,
критерий качества.
Рассмотрим их подробнее.

1) Промежуток управления. Прежде всего задачи оптимального управления разделяются на непрерывные, рассматриваемые на некотором промежутке времени $T = [t_{0},t_{f}]$, и дискретные, в которых динамический процесс рассматривается в дискретные моменты времени $k = 0,1,...N$, где $N$ — натуральное число.

По продолжительности процесса различаются задачи с фиксированным и нефиксированным временем окончания процесса. Выделяются также задачи на бесконечном интервале.

2) Математическая модель. Динамика изучаемого процесса моделируется, как правило, дифференциальными (для непрерывных систем)

\begin{equation}\label{1v}
\dot{x}(t) = f(x(t),u(t),t), t \in [t_0,t_f],
\end{equation}
или разностными уравнениями (для дискретных систем)

$$x(k + 1) = f(x(k),u(k),k),k = 0,1,...,$$
где $n$-вектор $x$ называется состоянием системы, $r$-вектор $u$ называется
управлением, функция
$ f : \mathbb{R} \times\  \mathbb{R}^r \times \mathbb{R} \rightarrow \mathbb{R}^n$ задана.

Число переменных состояния $n$ называется порядком системы управления, число $r$ — числом входов.

Далее будем рассматривать непрерывные системы вида (\ref{1v}).

3) Класс управлений и ограничения на них. Для непрерывного процесса управления указывается класс функций, из которого выбираются управления. Это могут быть: измеримые, дискретные, кусочно-непрерывные, гладкие, импульсные функции и т.д.

Кроме класса доступных управлений задается множество
$U \subset\ \mathbb{R}$ — множество допустимых значений управления. Как правило, $U$ — компакт в $\mathbb{R}^r$.

Далее будем рассматривать управления из класса кусочно-непрерывных функций.

\begin{definition}Кусочно-непрерывная функция $u(\cdot) = (u(t),t \in [t_{0},t_{f}])$ называется доступным управлением, если $u(t) \in U, t \in [t_{0},t_{f}].$
\end{definition}

4) Ограничения на фазовую траекторию. Ограничения на переменные состояния могут накладываться:\begin{itemize}
\item в начальный момент времени $t_{0}$:
$$x(t_{0}) \in X_{0};$$
\item в конечный момент времени $t_{f}$ --- такие ограничения называются терминальными: $$x(t_{f}) \in X_{f};$$
\item в изолированные моменты $t_{i} \in [t_{0},t_{f}], i = \overline{1,m},$ из промежутка управления — промежуточные фазовые ограничения:
$$X(t_{i}) \in X_{i},i = \overline{1,m},$$
\item на всем промежутке управления — фазовые ограничения:
$$x(t) \in X(t),t \in [t_{0},t_{f}],$$ где $X_{0}, X_{f}, X_{i}, i = \overline{1,m}, X(t), t \in [t_0,t_f],$ — заданные подмножества пространства состояний.
\end{itemize}
 Задача управления с $x(t_f) \in X_f $ называется:\begin{itemize}
  \item задачей со свободным правым концом траектории, если
 $X_f = \mathbb{R}^n$, \item задачей с закрепленным правым концом траектории, если $X_{f} = \{x_{f}\}$, \item задачей с подвижным правым концом траектории, если $X_{f}$ содержит более одной точки и не совпадает с $R^{n}$.
\end{itemize}
 Аналогичная классификация имеет место для задач с ограничениями на левый конец траектории $x_{0} \in X_{0}$.

  Выделяют также смешанные ограничения, учитывающие связи между переменными состояния и переменными управления:
$$(u(t),x(t)) \in S \subseteq \mathbb{R}^r \times \mathbb{R}^n,t \in [t_{0},t_{f}[.$$ \begin{definition} Доступное управление $u(\cdot)$ называется допустимым (или, программой), если оно порождает траекторию $x(\cdot)=(x(t), t \in [t_0,t_f]$, удовлетворяющую всем заданным ограничениям задачи. \end{definition}

5) Критерий качества. Качество допустимого управления оценивается так называемым критерием качества

 Существуют четыре типа критерия качества:

i) критерий качества Майера (терминальный критерий)
$$J(u) = \varphi(x(t_{f})),$$

ii) критерий качества Лагранжа (интегральный критерий)
$$J(u) =\int^{t_{f}}_{ t_{0}}
f_{0}(x(t),u(t),t)dt,$$

iii) критерий качества Больца
$$J(u) = \varphi(x(t_{f})) +
\int^{t_{f}}_{ t_{0}}
f_0(x(t),u(t),t)dt,$$

iv) задачи быстродействия (являются задачами с нефиксированной продолжительностью процесса).
$$J(u) = t_{f} - t_{0} \rightarrow \min.$$
\begin{definition} Допустимое управление $u^{0}(\cdot)$ называется оптимальным управлением (оптимальной программой), если на нем критерий качества достигает экстремального значения (min или max):
$$J(u^0) = extr J(u),$$

где минимум (максимум) берется по всем допустимым управлениям.
\end{definition}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Принцип максимума и динамическое программирование}\label{1sec:pm} % xxx заменить на свою метку
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
В теории оптимального управления существует два фундаментальных результата: принцип максимума Л.С. Понтрягина\cite{Pontryagin} и динамическое программирование Р. Беллмана.\cite{Bellman} Приведем эти результаты на примере простейшей задачи оптимального управления.

 $$J(u) = \varphi(x(t_{f})) +
\int^{t_{f}}_{ t_{0}}
f_0(x(t),u(t),t)dt \rightarrow \min, $$
 \begin{equation}\label{tr2}\dot{x}(t)=f(x(t),u(t),t), x(t_0)=x_0,\end{equation}
$$u(t) \in U, t\in [t_0,t_f].$$

Задача названа простейшей, поскольку не содержит ограничений на состояния, а только ограничения на управления.

\subsection{Принцип максимума Понтрягина}

Принципом максимума называется основное необходимое условие оптимальности в задачах оптимального управления, связанное с максимизацией гамильтониана:

$$H(x,\psi, u, t) = \psi 'f(x, u, t) - f_0(x, u, t) = \sum^n_{j=1} \psi_j f_j(x, u, t) - f_0(x, u, t).$$ Здесь $\psi = \psi (t) \in \mathbb{R}^n $ --- сопряженная переменная.
\begin{theorem}Пусть $u^0(\cdot), x^0(\cdot)$ — оптимальное управление и траектория в задаче (\ref{tr2}), $\psi^0(\cdot)$ — соответствующее решение сопряженной системы
$$ \dot{\psi}^0(t)= -\frac{\partial H}{\partial x}(x^0(t),\psi^0(t),u^0(t),t),$$ с начальным условием
$$\psi^0(t_f) = - \frac{\partial\varphi}{\partial x}(x^0(t_f)). $$
Тогда для любого $t \in [t_0,t_f]$, управление $u^0(t)$ удовлетворяет условию:
$$H(x^0(t),\psi^0(t),u^0(t),t) = \max_{v\in U}
H(x^0(t),\psi^0(t),v,t), t \in [t_0,t_f].$$
\end{theorem}

Для того чтобы решить задачу с помощью принципа максимума обычно поступают следующим образом. Функцию $H(x, \psi ,u,t)$ рассматривают как функцию $r$  переменных $u = (u_1,...,u_r).$ Далее проводят поточечную оптимизацию для каждого фиксированного набора $(x, \psi ,t)$
\begin{equation}\label{krz}u(x, \psi ,t) = \arg \max_{v \in U} H(x, \psi , v, t).\end{equation}
Если исходная задача (\ref{tr2}) имеет решение, функция (\ref{krz}) определена на непустом множестве значений $(x, \psi , t).$

Пусть  $u$ в виде (\ref{krz}) найдена, тогда можно рассмотреть следующую систему с граничными условиями:
$$ \dot{x} =\frac{\partial{H}}{\partial{\psi}}(x, \psi , u(x, \psi , t), t) = f(x, \psi , u(x, \psi , t), t), \ x(t_0) = x_0,$$
$$ \dot{\psi } = - \frac{\partial{H}}{\partial{x}}(x, \psi , u(x, \psi , t), t), \  \psi (t_f) = -\frac{\partial{\varphi(x(t_f))}}{\partial{x}}.$$
Таким образом получена специальная краевая задача, которая называется краевой задачей принципа максимума.

Можно ожидать, что имеются лишь отдельные изолированные пары функций $x(\cdot), \psi (\cdot),$ удовлетворяющие краевой задаче принципа максимума. Подставив одну такую пару в (\ref{krz}), получим:
\begin{equation}\label{prtn}u(t) = u(x(t), \psi (t),t), t \in [t_0, t_f],\end{equation}
которая удовлетворяет принципу максимума и, значит, может претендовать на роль оптимального управления, а функция $x(t) = x(t\mid t_0,x_0,u(\cdot)), t\in [t_0, t_f],$ --- на роль оптимальной траектории в задаче.

Отметим, что принцип максимума в задаче (\ref{tr2}) является лишь необходимым условием оптимальности, поэтому построенное управление не может быть оптимальным. Построенная функция называется экстремалью Понтрягина (\ref{prtn}).
\subsection{Динамическое программирование}

Рассмотрим задачу (\ref{tr2}) и предположим, что она имеет решение. Следуя динамическому программированию\cite{Bellman}, погрузим задачу (\ref{tr2}) в семейство задач
$$ J_{\tau ,z}(u) = \varphi (x(t_f)) + \int^{t_{f}}_{\tau }
f_0(x(t),u(t),t)dt \rightarrow \min, $$
 \begin{equation}\label{dp1}\dot{x}(t)=f(x,u), \  x(\tau )=z,\end{equation}
$$u(t) \in U, \ t\in T = [\tau ,t_f],$$
зависящих от скаляра $\tau \in T$ и $n$-вектора $z.$

Пару $(\tau , z)$ назовем позицией в задаче (\ref{tr2}). Обозначим через $$B(\tau ,z) = \min J_{\tau ,z} (u)$$
минимальное значение критерия качества в задаче (\ref{dp1}) для позиции $(\tau , z)$. Если для позиции  $(\tau , z)$ задача (\ref{dp1}) не имеет решения, положим $B(\tau ,z) =  +\infty$. Пусть $$X_{\tau } = \{z \in \mathbb{R}: B(\tau ,z) < +\infty \}.$$
Функцию\begin{equation}\label{fb} B(\tau ,z), z \in X_{\tau}, \tau \in T,\end{equation} называют функцией Беллмана.

Уравнение в частных производных, которому удовлетворяет функция (\ref{fb}), называют уравнением Беллмана
\begin{equation*}\label{ub} -\frac{\partial B(\tau,z)}{\partial\tau} = \min_{v \in U}\left\{ \frac{\partial B'(\tau,z)}{\partial z}f(z,v) + f_0(z,v)\right\}, z \in X_\tau, \tau \in T.\end{equation*}
Выделяя из семейства (\ref{dp1}) задачу с $\tau = t_f$, находим граничное условие для уравнения Беллмана
\begin{equation*}\label{gusl}B(t_f,z)=\begin{cases}
\varphi(z), если z \in X, \\
+\infty , z \not\in X.
\end{cases}\end{equation*}
\bigskip

Схема применения динамического программирования состоит в следующем: для задач составляется уравнение Беллмана. По решению уравнения строиться позиционное решение.

Основным преимуществом динамического программирования является тот факт, что получаемое решение имеет вид управления типа обратной связи, тогда как принцип максимума строит только программное решение. Подробно обратные связи обсуждаются в следующем разделе.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Классический подход к построению оптимальных обратных связей}\label{1sec:MPC}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Классический подход к построению оптимальной обратной связи продемонстрируем на примере следующей задачи:
\begin{equation} \label{1problem}
    J(u) = \varphi(x(t_f))\to \min,
    \end{equation}
\begin{equation} \label{2problem}
    \dot{x}=f(x,u,t),\ x(t_0)=x_0
     \end{equation}
\begin{equation} \label{3problem}
  	x(t)\in X\in\mathbb{R}^n
     \end{equation}
\begin{equation} \label{4problem}
  	 u(t)\in U\in\mathbb{R}^r,\  t\in [t_0, t_f]
     \end{equation}


В поставленной задаче нужно минимизировать критерий качества (\ref{1problem}) на траекториях системы (\ref{2problem}), которые в каждый момент времени лежат в заданном множестве $X$, согласно (\ref{3problem}), с помощью ограниченных управляющих воздействий (\ref{4problem}).

В (\ref{1problem}) - (\ref{4problem}):  $t_0, t_f$ --- заданы,\\
$x = x(t)\in\mathbb{R}^n$ --- состояния системы управления в момент $t$,\\
$u = u(t)\in\mathbb{R}^r$ --- значения управляющего воздействия в $t$.\\
$f:\mathbb{R}^n\times\mathbb{R}^r\times\mathbb{R}^n$ обеспечивает существование и продолжимость решения уравнения (\ref{2problem}) на промежутке времени $T = [t_0; t_f]$. \\

Задачу (\ref{1problem}) -- (\ref{4problem}) будем рассматривать в классе кусочно-непрерывных управляющих воздействий $u$.


Допустимое программное управление (программа) --- кусочно-непрерывная функция $u(t)\in U$, $t\in [t_0, t_f]$, если она порождает траекторию $х(t)$, $t\in [t_0, t_f]$, системы (\ref{2problem}), удовлетворяющей (\ref{3problem}).

Допустимое программное управление --- оптимальное (оптимальная программа), если на нем критерий качества (\ref{1problem}) достигает оптимального значения:
$J(u^0) = \min J(u)$, где минимум берется по всем программам.

Для введения понятия классической оптимальной обратной связи погрузим задачу (\ref{1problem}) -- (\ref{4problem}) в следующее семейство задач:
\begin{equation} \label{5problem}
    \varphi(x(t_f))\to \min,
    \end{equation}
$$
    \dot{x}=f(x,u,t),\ x(\tau)=z,
    $$
$$
  	x(t)\in X, \ \ u(t)\in U,\  t\in [\tau, t_f].
  $$

Пусть $u^0(t|\tau,z),\ t\in T_\tau$, --- оптимальная программа задачи (\ref{5problem}) для позиции $(\tau,z)$; $X_\tau$ --- множество состояний $z$ таких, что для позиции $(\tau,z)$ существуют программные решения задачи (\ref{5problem}).

Функция
\begin{equation} \label{6problem}
    u^0(\tau,z) = u^0(t|\tau,z), \ z\in X_{\tau}, \tau\in T,
     \end{equation}
     --- оптимальная обратная связь.

Построение (\ref{6problem}) --- синтез оптимальной системы управления.

Подстановка функции (\ref{6problem}) в уравнение (\ref{3problem}) --- замыкание системы управления
\begin{equation} \label{7problem}
    \dot{x}=f(x,u^0(t,x),t),\ x(t_0)=x_0
     \end{equation}

Полученное уравнение --- математическая модель оптимальной автоматической системы управления.

Для любого состояния $x_0$ решение уравнения (\ref{7problem}) с начальным состоянием $x(t_0)=x_0$ --- оптимальная траектория для задачи (\ref{1problem}) -- (\ref{4problem}).

Отметим, что если оптимальная обратная связь построена в классе кусочно-непрерывных управлений, то во многих задачах уравнение (\ref{7problem}) представляет собой
дифференциальное уравнение с разрывной правой частью и, вообще говоря, не имеет классического решения. В этих случаях используют обобщенное решение.

Чтобы избежать аналитических трудностей, таких как определение решения замкнутой системы управления, в задаче оптимального управления (\ref{1problem}) -- (\ref{4problem})
перейдем от класса кусочно-непрерывных управлений к дискретным управлениям.

Разобьем $[t_0, t_f]$ на $N\in \mathbb{N}$ частей: $T_h = \{t_0, t_0 + h, ..., t_f - h\}$, где $h = \frac{t_f - t_0}{N}$ --- период квантования.

Дискретное управление имеет вид:
\begin{equation*}
    u(t) = u(s),\ t\in [s, s+h],\ s\in T_h.
     \end{equation*}

Понятие программы и оптимальной программы в классе дискретных управлений аналогично определению в классе кусочно-непрерывных управлений.

Семейство, в которое погружается задача (\ref{1problem}) -- (\ref{4problem}) будет выглядеть так же как и (\ref{5problem}). Однако теперь  семейство зависит от $z\in X$, $\tau\in T_h$.

Оптимальная \textit{дискретная} обратная связь --- функция
\begin{equation*} \label{9problem}
    u^0(\tau,z) = u^0(t|\tau,z),\  z \in X_\tau,\ \tau \in T_h.
\end{equation*}

Еще раз обратим внимание на то, что динамическое программирование строит решение в виде обратной связи. Однако, его реализуемость на практике сдерживается так называемым проклятием размерности. Для задач с $n>3$, содержащими ограничения на управления, динамическое программирование, как правило, не применимо.

\section{Оптимальное управление в реальном времени и реализация оптимальной обратной связи}\label{1sec:real-time}

Проанализируем, как используется оптимальная дискретная обратная связь $u^0(\tau,z) = u^0(t|\tau,z),\ \tau\in T_h,\ z\in \mathbb{X_\tau}$, в конкретном процессе управления.

Процесс начинается в момент $t_0$ с подачи на вход
объекта управляющего воздействия $u^*(t) \equiv u^*(t_0) = u^0(t_0,x_0)$, $t\ge t_0$.

В момент времени $\tau = t_0+h$ становится известным состояние объекта $x^*(t_0+h)$. Здесь верхний индекс $^*$ означает, что состояние $x^*(t_0+h)$ может отличаться от идеального состояния $x(t_0+h)$ системы (\ref{2problem}) в силу немоделируемых возмущений. Временем отыскания значения $u^0(t_0+h, x^*(t_0+h))$ пренебрежем. С момента $t_0 + h$ на вход объекта подается управляющее воздействие
$u^*(t) \equiv u^*(t_0+h) = u^0(t_0+h, x^*(t_0+h))$, $t\ge t_0+h$.

Продолжая этот процесс, в момент времени $\tau\in T_h$ измеряется состояние объекта $x^*(\tau)$, и с момента $\tau$ на вход объекта подается управляющее воздействие $u^*(t) \equiv u^*(\tau) = u^0(\tau, x^*(\tau))$, $t\ge \tau$.

Получается последовательность состояний объекта
\begin{equation*}\label{1x}
    x^*(t_0) = x_0, \  x^*(t_0+h),\  \ldots, \  x^*(\tau),\  \ldots, \ x(t_f),
    \end{equation*}
и соответствующая ей последовательность управляющих воздействий $u^*(t_0)$, $u^*(t_0+h)$, $\ldots$, $u^*(\tau)$, $\ldots$, $u(t_f-h)$. Они удовлетворяют тождеству
$$
    x^*(t) \equiv f(x^*(t), u^*(t), t) + w^*(t), \ t\in T, \ x^*(t_0) = x_0
    $$
где
\begin{equation} \label{9problem}
    u^*(t), t\in T: \ u^*(t) = u^0(\tau,x^*(\tau)), \ t\in [\tau, \tau + h], \tau\in T_h,
     \end{equation}
--- реализация оптимальной обратной связи (\ref{1problem}) в конкретном процессе управления.

Отсюда видно, что в конкретном процессе управления оптимальная обратная связь (\ref{1problem}) не используется целиком на всей области ее определения.
Нужны лишь ее значения (\ref{9problem}) вдоль одной последовательности измеряемых состояний физического объекта $x^*(\tau), \tau\in T_h$, и достаточно уметь
для каждой текущей позиции $(\tau,x^*(\tau)), \tau\in T_h$, вычислять значение реализации
$u^*(t) = u^0(\tau, x^*(\tau)),\ t\in [\tau, \tau + h]$, оптимальной обратной связи за время $s(\tau)<h$.

Будем говорить, что процесс управления осуществляется в реальном времени, если для каждого текущего момента $\tau\in T_h$ значение $u^*(\tau)$
вычисляется за время $s(\tau)<h$, т.е. до получения следующего измерения $x^*(\tau+h)$. Устройство, способное реализовать оптимальную обратную связь в реальном времени будем называть оптимальным регулятором.

Таким образом, с использованием принципа управления в реальном времени задача синтеза оптимального управления типа обратной связи сводится к построению алгоритма работы оптимального регулятора.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теория управления по прогнозирующей модели}\label{2sec:mpc-general}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Постановка задачи
% $$
% \begin{cases}
%     \dot{x} = f(x, u),\ u(t) \in U, \\
%     x(0) = x_0 ,\ x(\tau) \in X.
% \end{cases}
% $$
% $$\min_{u} J = \int_{t}^{\inf} F(x(\tau), u(\tau)) d\tau$$


% $\varphi(t)$ --- устойчива, если $\forall \varepsilon > 0 \ \exists \delta(\varepsilon) > 0 \ \| x(0) - \varphi(0)\| \le \delta \Rightarrow \| x(t) - \varphi(t) \| \le \varepsilon$\\

% Ассимптотическая устойчивость:
% \begin{enumerate}
%     \item $\varphi (t)$ --- устойчива
%     \item $\exists \delta \ \| x(0) - \varphi(0)\| \le \delta \ \lim \lim_{t\to\infty} \| x(t) - \varphi(t) \| = 0$\\
% \end{enumerate}
% Динамика:
% $$
% \begin{cases}
%     \dot{x} = f(x, u),\ x \in \mathbb{R}^n, \\
%     x(0) = x_0 ,\ u \in  \mathbb{R}^m.
% \end{cases}
% $$ \\
% Ограничения: \\
% $$x(t) \in X,\ u(t) \in U \ \forall t \ge 0.$$\\
% Задача MPC:
% В момент времени $t$, зная начальное состояние $x(t)$

% $$ \min_{\overline{u}(:,t)} J(x(t), \overline{u}(\cdot,t)) $$ \\
% $\overline{u}$ --- предсказанное \\
% $u(t, \tau)$ --- $u(t)$ в предсказанный момент времени $\tau$
% $$ J(x(t), \overline{u}(\cdot,t)) = \int_{t}^{t + T} L(\overline{x}(\tau, t), \overline{u}(\tau, t)) d\tau,$$ \\
% $$\dot{\overline{x}} = f(\overline{x}, \overline{u}), \\$$
% $$\overline{x}(t,t) = x(t), \\$$
% $$\overline{u}(\tau, t) \in U, \\$$
% $$\overline{x}(\tau, t) \in X, \ \forall \tau \in [t, t + T]. $$

% $L$ --- стоимость этапа,\ $\delta$ --- шаг дискретизации.

Model Predictive Control (MPC) --- управление по прогнозирующей модели --- подход к управлению линейными и нелинейными динамическими системами, в основе которого лежит решение в реальном времени последовательности так называемых \textit{прогнозирующих} задач оптимального управления. Прогнозирующие задачи, в отличие от исходной, формулируются на конечном горизонте управления (для эффективного численного решения),  учитывают текущие состояния исследуемого объекта управления и ограничения на траектории и управляющие воздействия, оценивают будущее поведение системы на основе целей управления на бесконечном горизонте, а также аппроксимируют эти цели \cite{ChenAllgower}.

В основе MPC лежат следующие принципы:
\begin{itemize}
    \item Для предсказания и оптимизации будущего поведения системы используется математическая модель управляемого процесса в пространстве состояний.
    \item Для выбранной математической модели формулируется прогнозирующая задача оптимального управления, которая решается в каждый конкретный момент времени. В данной задаче: \begin{enumerate}
        \item Конечный промежуток управления.
        \item Начальное состояние математической модели совпадает с измеренным текущим состоянием физического объекта управления.
        \item Критерий качества отражает цели управления: если целью является стабилизация объекта управления, то критерием качества выступает отклонение траектории объекта от положения равновесия.
        \item Учтены ограничения на траекторию и управляющие воздействия;
    \end{enumerate}
    \item Оптимальное управление прогнозирующей задачи (предсказанное управляющее воздействие) применяется к объекту в текущий момент времени и до тех пор пока не будет измерено следующее состояние объекта, затем оптимизация повторяется.
\end{itemize}

Поскольку в каждый момент времени в задаче оптимального управления учитывается текущее состояние, результирующее управление представляет собой обратную связь.

Популярность MPC в теоретических исследованиях и на практике обусловлена следующими свойствами, которыми не обладают другие методы теории управления:
\begin{itemize}
    \item Критерий качества в прогнозирующей задаче позволяет учитывать экономические требования к процессу управления (например, минимизацию энергетических затрат);
    \item Учитываются жесткие ограничения на фазовые и управляющие переменные;
    \item Метод применим к нелинейным и многосвязным системам.
\end{itemize}

Задачи стабилизации и регулирования считаются основными и исторически первыми приложениями MPC. Рассмотрим результаты, полученные в теории MPC для задачи стабилизации \cite{ChenAllgower}. 

Как было отмечено выше, основная идея MPC состоит в том, чтобы использовать математическую модель процесса в пространстве состояний, чтобы предсказывать и оптимизировать поведения динамической системы в дальнейшем. Будем считать, что модель, которая используется для предсказаний точно описывает процесс управления: на объект не действует возмущения и нет неучтенных различий между моделью и физическим объектом. Такие схемы MPC называются номинальными.

Будем исследовать нелинейную, дискретную, стационарную систему:
\begin{equation} \label{1-5-1}
    x(t+1)=f(x(t),u(t)),\ x(0)=x_0.
\end{equation}
Здесь $x(t) \in X \subseteq \mathbb{R}^n$ --- состояние системы в момент времени $t,\ u(t) \in U \subseteq \mathbb{R}^r$ --- управляющее воздействие в момент $t,\ t \in I \ge 0$ --- дискретное время. Предполагается, что функция $f : \mathbb{R}^n \times \mathbb{R}^r \to \mathbb{R}^n$ непрерывна.

Начальное состояние системы (\ref{1-5-1}) задано:
$$
    x(0)=x_0 \in X.
$$

На состояния и управляющие воздействия $u$ накладываются ограничения  следующего вида:
\begin{equation}\label{1-5-2}
    (x(t),\ u(t)) \in Z \subseteq X \times U,\ t \in \mathbb{I}_{\ge 0}
\end{equation}
--- смешанные ограничения. Будем считать, что множество $Z$ компактно.

Цель (стабилизирующего) MPC --- построить обратную связь $u(x)$, при которой замкнутая система
\begin{equation}\label{1-5-3}
    x(t+1)=g(x(t))=f(x(t),\ u(x(t))),\ x(0)=x_0,
\end{equation}
будет устойчива в некотором заданном положении равновесия (заданном множестве), при этом переходный процесс не нарушает ограничения (\ref{1-5-2}) $\forall t \in \mathbb{I}_{\ge 0}$.

\begin{definition}
    Точка $x^{*}$ --- положение равновесия для системы (\ref{1-5-3}), если выполняется $x^{*} = g(x^{*})$.
\end{definition}

\begin{definition}
    Тривиальное решение $x^*$ = 0 (\ref{1-5-3}) называется устойчивым по Ляпунову, если $\forall \varepsilon > 0,\ \exists \delta > 0$, что неравенство $|x(t, x_0)|| \le \epsilon$ выполнено , как только $|x_0| \le \delta$
\end{definition}

\begin{definition}
    Тривиальное решение $x^*$ = 0 (\ref{1-5-3}) называется асимптотически устойчивым по Ляпунову, если оно устойчиво и выполняется условие $\lim_{t \to \infty} ||x(t, x_0)|| = 0$ для всякого $x$ с начальным условием $x_0$, лежащим в достаточно малой окрестности нуля
\end{definition}

Опишем базовый алгоритм MPC.  Идея алгоритма состоит в том, чтобы в каждый момент $t \in \mathbb{I}_{\ge 0}$ оптимизировать дальнейшее поведение системы (\ref{1-5-1}) на конечном горизонте $N \ge 2$ и использовать первое значение полученного оптимального управления в качестве значения обратной связи для момента $t$. Под "оптимизацией будущего поведения"{} понимается решение прогнозирующей задачи оптимального управления.

Понятно, что далее необходимо различать состояния объекта управления $x(t),\ t \in  \mathbb{I}_{\ge 0}$, которые измеряются в каждом конкретном процессе управления, и состояния математической модели, которая используется для предсказаний и формулировки прогнозирующей задачи оптимального управления. Поэтому состояния математической модели будем будем обозначать $x(k|\ t),\ k \in \mathbb{I}_{[0,N-1]}$. Они изменяются согласно уравнению
\begin{equation}\label{1-5-4}
    x(k+1|\ t)=f(x(k|\ t),\ u(k|\ t)),\ x(0|\ t)=x(t),\ k \in \mathbb{I}_{[0,N-1]}.
\end{equation}

Здесь аргумент $t$ после черты подчеркивает зависимость от текущего момента, для которого проводится оптимизация. Начальное состояние --- текущее состояние объекта управления $x(t)$.

Ограничения (\ref{1-5-2}), записанные для состояний математической модели (\ref{1-5-4}), имеют вид:
$$
    (x(k|\ t),\ u(k|\ t)) \in Z,\ k \in \mathbb{I}_{[0,N-1]}.
$$

Помимо приведенных смешанных ограничений, в задачу, чаще всего, добавляются ограничения в терминальный момент времени. "Терминальные элементы"{} прогнозирующей задачи более подробно будут рассмотрены ниже после ее формулировки.

Оставшийся элемент прогнозирующей задачи оптимального управления --- критерий качества. В задачах стабилизации критерий качества выбирается исследователем, практиком, и является, скорее, параметром настройки схемы MPC. Например, в задаче стабилизации критерий качества выбирается из соображений штрафа любого состояния $x \in X$, отклоняющегося от состояния равновесия $x^{*}$. Также часто штрафуются отклонения управления $u \in U$ от значения $u^{*}$.
Критерий качества будет состоять из терминальной стоимости $V_f (x(N |\ t))$ и суммарной стоимости переходного процесса, т.е. это будет критерий качества типа Больца. Терминальная стоимость будет рассмотрена ниже, при обсуждении терминальных элементов задачи оптимального управления. Стоимость переходного процесса для дискретных систем задается суммой стоимостей за каждый этап:
$$
\sum_{k=0}^{N-1}l(x(k|\ t), u(k|\ t)).
$$

В литературе функция $l : \mathbb{R}^n \times \mathbb{R}^r \to \mathbb{R}$ называется стоимостью этапа. Считается, что она непрерывна, а также:
\begin{enumerate}
    \item $l(x^{*},\ u^{*}) = 0$, т.е. стоимость обращается в нуль в точке равновесия;
    \item существует функция $\alpha_1$ класса $\mathcal{K}_{\infty}$, что выполняется $$
    l(x,\ u) \ge \alpha_1(|x - x^{*}|),\ \forall (x,\ u) \in Z.
    $$
\end{enumerate}

Таким образом, прогнозирующая задача оптимального управления для момента времени $t$ имеет вид:
\begin{equation}\label{1-5-5}
    \mathcal{P}(t): \ \ \ \ V(x(t))= \min_{u(\cdot \ |\ t)} \sum_{k=0}^{N-1}l(x(k|\ t),\ u(k|\ t)) + V_f(x(N|\ t)),
\end{equation}
при условиях
$$
    x(k+1|\ t)=f(x(k|\ t),\ u(k|\ t)),\ k \in \mathbb{I}_{[0,N-1]},
$$
$$
    x(0|\ t) = x(t),
$$
$$
    (x(k|\ t),\ u(k|\ t)) \in Z,\ k \in \mathbb{I}_{[0,N-1]},
$$
$$
    x(N|\ t) \in X_f.
$$

В задаче (\ref{1-5-5}) обсуждавшиеся выше "терминальные элементы":
\begin{itemize}
    \item терминальная стоимость $V_f(x(N|t))$ в критерии качества;
    \item терминальное ограничение $x(N|\ t) \in X_f$, где $X_f$ --- терминальное множество.
\end{itemize}

Именно условия на эти элементы обеспечивают устойчивость замкнутой системы несмотря на то, что решается задача с конечным горизонтом.

Далее используем следующие обозначения:

$u^0(\cdot \ |\ t) = \{u^0 (0\ |\ t),\ \dots,\ u^0(N - 1\ |\ t)\}$ --- оптимальное (программное) управление задачи $\mathcal{P}(t)$;

$x^0(\cdot \ |\ t) = \{x^0(0\ |\ t),\ \dots,\ x^0(N\ |\ t)\}$ ---  соответствующая траектория;

$X_N$ — множество всех состояний $x \in X$, для которых существует решение задачи (\ref{1-5-5}) с $x(t) = x$.

Базовый алгоритм MPC состоит в следующем:

Для каждого $t \in \mathbb{I} \ge 0$
\begin{enumerate}
    \item измерить состояние $x(t) \in X$ системы (\ref{1-5-1});
    \item решить задачу (\ref{1-5-5}) с начальным условием $x(0|t) = x(t)$, получить ее решение $u^0(\cdot|t)$;
    \item подать на вход системы (\ref{1-5-1}) управляющее воздействие: \begin{equation}\label{1-5-6}
        u_{MPC}(t) := u^0(0|t).
    \end{equation}
\end{enumerate}

Таким образом, в каждый момент $t \in \mathbb{I} \ge 0$ на систему подается управляющее воздействие (\ref{1-5-6}), которое неявно зависит от текущего состояния $x(t)$.

Соответственно, замкнутая система имеет вид:
$$
    x(t+1)=f(x(t),u^0(0|t)),\ t \in \mathbb{I} \ge 0.
$$

Асимтотическая устойчивость замкнутой системы обеспечивается правильным выбором терминальных элементов. Самый простой способ состоит в том, чтобы принять терминальное ограничение равенство 
$$
    x(N|t) = x^*.
    $$
Другой популярный на практике подход описан в работе \cite{ChenAllgower}. 